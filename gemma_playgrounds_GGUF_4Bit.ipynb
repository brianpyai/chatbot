{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianpyai/chatbot/blob/main/gemma_playgrounds_GGUF_4Bit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-czlAOa2dN4g",
        "outputId": "534b4ccc-e707-42f5-d60f-cba6c5344b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio==4.22.0\n",
            "  Using cached gradio-4.22.0-py3-none-any.whl (17.1 MB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.22.0)\n",
            "  Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (4.2.2)\n",
            "Collecting fastapi (from gradio==4.22.0)\n",
            "  Using cached fastapi-0.110.2-py3-none-any.whl (91 kB)\n",
            "Collecting ffmpy (from gradio==4.22.0)\n",
            "  Using cached ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.13.0 (from gradio==4.22.0)\n",
            "  Using cached gradio_client-0.13.0-py3-none-any.whl (311 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio==4.22.0)\n",
            "  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio==4.22.0)\n",
            "  Using cached orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (2.7.0)\n",
            "Collecting pydub (from gradio==4.22.0)\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio==4.22.0)\n",
            "  Using cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio==4.22.0)\n",
            "  Downloading ruff-0.4.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==4.22.0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.22.0)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (0.9.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (4.11.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==4.22.0)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.13.0->gradio==4.22.0) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.13.0->gradio==4.22.0)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.22.0) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.22.0) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.22.0) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.22.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.22.0) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio==4.22.0)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.22.0) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.22.0) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio==4.22.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.22.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.22.0) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.22.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.22.0) (2.18.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.22.0) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio==4.22.0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio==4.22.0)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.22.0) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio==4.22.0)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.22.0) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.22.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.22.0) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio==4.22.0) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.22.0) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=2d49579cb6e78cb6d4be066ac1b362a2eeba677cb7ca920273cbbd4e0fb37c7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, colorama, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 colorama-0.4.6 fastapi-0.110.2 ffmpy-0.3.2 gradio-4.22.0 gradio-client-0.13.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.1 pydub-0.25.1 python-multipart-0.0.9 ruff-0.4.1 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 uvicorn-0.29.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install gradio==4.22.0 transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ8HCwYutHId",
        "outputId": "6410110c-9241-49d9-cc2e-e6c61f936d95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\n",
        "#@title Built llama-cpp-python with BLAS or CUDA automatically, wait for few minutes .\n",
        "import os,torch\n",
        "\n",
        "\n",
        "if torch.cuda.is_available ():\n",
        "    cmd='CMAKE_ARGS=\"%s\" pip install llama-cpp-python==0.2.62' % \"-DLLAMA_CUBLAS=on\"\n",
        "else:\n",
        "    cmd='CMAKE_ARGS=\"%s\" pip install llama-cpp-python==0.2.62' % \"-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS\"\n",
        "\n",
        "os.system (cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOxIBjXDN2ee",
        "outputId": "0d734cbc-1dc0-420e-b016-4730e952baed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from ./dolphin-2.9-llama3-8b.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = .\n",
            "llama_model_loader: - kv   2:                           llama.vocab_size u32              = 128258\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,128258]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,128258]  = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128258]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dolphin-2.9-llama3-8b.Q4_K_M.gguf 3thn/dolphin-2.9-llama3-8b-GGUF\n",
            "3thn/dolphin-2.9-llama3-8b-GGUF dolphin-2.9-llama3-8b.Q4_K_M.gguf True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128256\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 128001\n",
            "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
            "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 258/128258 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = BPE\n",
            "llm_load_print_meta: n_vocab          = 128258\n",
            "llm_load_print_meta: n_merges         = 280147\n",
            "llm_load_print_meta: n_ctx_train      = 8192\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 500000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 8.03 B\n",
            "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
            "llm_load_print_meta: general.name     = .\n",
            "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
            "llm_load_print_meta: EOS token        = 128256 '<|im_end|>'\n",
            "llm_load_print_meta: PAD token        = 128001 '<|end_of_text|>'\n",
            "llm_load_print_meta: LF token         = 128 'Ä'\n",
            "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
            "llm_load_tensors:        CPU buffer size =  4685.32 MiB\n",
            "........................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: freq_base  = 500000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   296.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\", 'tokenizer.ggml.padding_token_id': '128001', 'tokenizer.ggml.eos_token_id': '128256', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'llama.context_length': '8192', 'general.name': '.', 'llama.vocab_size': '128258', 'general.file_type': '15', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
            "Using gguf chat template: {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}\n",
            "Using chat eos_token: <|im_end|>\n",
            "Using chat bos_token: <|begin_of_text|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://150c6fda8883d28d16.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "{'text': \"Using Javascript and CSS to create a beautiful lunar calendar, accurately displaying today's date, and all codes within the same HTML.\", 'files': []}\n",
            "Creating 'Creating'\n",
            " an ' an'\n",
            " interactive ' interactive'\n",
            " and ' and'\n",
            " visually ' visually'\n",
            " appealing ' appealing'\n",
            " Lunar ' Lunar'\n",
            " Calendar ' Calendar'\n",
            " using ' using'\n",
            " JavaScript ' JavaScript'\n",
            " ( ' ('\n",
            "JS 'JS'\n",
            ") ')'\n",
            " and ' and'\n",
            " Casc ' Casc'\n",
            "ading 'ading'\n",
            " Style ' Style'\n",
            " Sheets ' Sheets'\n",
            " ( ' ('\n",
            "CSS 'CSS'\n",
            ") ')'\n",
            " can ' can'\n",
            " be ' be'\n",
            " quite ' quite'\n",
            " engaging ' engaging'\n",
            ". '.'\n",
            " To ' To'\n",
            " assist ' assist'\n",
            " you ' you'\n",
            " with ' with'\n",
            " this ' this'\n",
            " task ' task'\n",
            ", ','\n",
            " we ' we'\n",
            "'ll \"'ll\"\n",
            " first ' first'\n",
            " need ' need'\n",
            " to ' to'\n",
            " understand ' understand'\n",
            " how ' how'\n",
            " the ' the'\n",
            " Lunar ' Lunar'\n",
            " Calendar ' Calendar'\n",
            " works ' works'\n",
            ".\n",
            "\n",
            " '.\\n\\n'\n",
            "A 'A'\n",
            " standard ' standard'\n",
            " Lunar ' Lunar'\n",
            " Calendar ' Calendar'\n",
            " follows ' follows'\n",
            " the ' the'\n",
            " phases ' phases'\n",
            " of ' of'\n",
            " the ' the'\n",
            " Moon ' Moon'\n",
            " over ' over'\n",
            " a ' a'\n",
            " twelve ' twelve'\n",
            "-month '-month'\n",
            " period ' period'\n",
            ", ','\n",
            " marking ' marking'\n",
            " the ' the'\n",
            " dates ' dates'\n",
            " of ' of'\n",
            " New ' New'\n",
            " Moon ' Moon'\n",
            ", ','\n",
            " Full ' Full'\n",
            " Moon ' Moon'\n",
            ", ','\n",
            " and ' and'\n",
            " Quarter ' Quarter'\n",
            " Mo ' Mo'\n",
            "ons 'ons'\n",
            ". '.'\n",
            " Each ' Each'\n",
            " month ' month'\n",
            " in ' in'\n",
            " the ' the'\n",
            " Lunar ' Lunar'\n",
            " Calendar ' Calendar'\n",
            " corresponds ' corresponds'\n",
            " to ' to'\n",
            " roughly ' roughly'\n",
            "  ' '\n",
            "29 '29'\n",
            ". '.'\n",
            "5 '5'\n",
            " days ' days'\n",
            " ( ' ('\n",
            "the 'the'\n",
            " average ' average'\n",
            " time ' time'\n",
            " it ' it'\n",
            " takes ' takes'\n",
            " for ' for'\n",
            " the ' the'\n",
            " Moon ' Moon'\n",
            " to ' to'\n",
            " orbit ' orbit'\n",
            " Earth ' Earth'\n",
            ").\n",
            "\n",
            " ').\\n\\n'\n",
            "Since 'Since'\n",
            " we ' we'\n",
            " are ' are'\n",
            " using ' using'\n",
            " JavaScript ' JavaScript'\n",
            " and ' and'\n",
            " CSS ' CSS'\n",
            " in ' in'\n",
            " the ' the'\n",
            " same ' same'\n",
            " HTML ' HTML'\n",
            " file ' file'\n",
            ", ','\n",
            " here ' here'\n",
            "'s \"'s\"\n",
            " how ' how'\n",
            " you ' you'\n",
            " can ' can'\n",
            " proceed ' proceed'\n",
            ":\n",
            "\n",
            " ':\\n\\n'\n",
            "1 '1'\n",
            ". '.'\n",
            " ** ' **'\n",
            "Structure 'Structure'\n",
            "**: '**:'\n",
            " Start ' Start'\n",
            " by ' by'\n",
            " creating ' creating'\n",
            " an ' an'\n",
            " HTML ' HTML'\n",
            " structure ' structure'\n",
            " that ' that'\n",
            " will ' will'\n",
            " serve ' serve'\n",
            " as ' as'\n",
            " the ' the'\n",
            " foundation ' foundation'\n",
            " of ' of'\n",
            " your ' your'\n",
            " calendar ' calendar'\n",
            ". '.'\n",
            " This ' This'\n",
            " could ' could'\n",
            " include ' include'\n",
            " elements ' elements'\n",
            " such ' such'\n",
            " as ' as'\n",
            " headers ' headers'\n",
            ", ','\n",
            " tables ' tables'\n",
            ", ','\n",
            " and ' and'\n",
            " div ' div'\n",
            "s 's'\n",
            ".\n",
            "\n",
            " '.\\n\\n'\n",
            "2 '2'\n",
            ". '.'\n",
            " ** ' **'\n",
            "Style 'Style'\n",
            "**: '**:'\n",
            " Use ' Use'\n",
            " CSS ' CSS'\n",
            " to ' to'\n",
            " design ' design'\n",
            " and ' and'\n",
            " beaut ' beaut'\n",
            "ify 'ify'\n",
            " this ' this'\n",
            " structure ' structure'\n",
            ". '.'\n",
            " You ' You'\n",
            " can ' can'\n",
            " determine ' determine'\n",
            " the ' the'\n",
            " layout ' layout'\n",
            " ( ' ('\n",
            "such 'such'\n",
            " as ' as'\n",
            " grid ' grid'\n",
            " or ' or'\n",
            " list ' list'\n",
            "), '),'\n",
            " color ' color'\n",
            " schemes ' schemes'\n",
            ", ','\n",
            " typography ' typography'\n",
            ", ','\n",
            " etc ' etc'\n",
            ".\n",
            "\n",
            " '.\\n\\n'\n",
            "3 '3'\n",
            ". '.'\n",
            " ** ' **'\n",
            "Script 'Script'\n",
            "**: '**:'\n",
            " Then ' Then'\n",
            " use ' use'\n",
            " JavaScript ' JavaScript'\n",
            " to ' to'\n",
            " make ' make'\n",
            " your ' your'\n",
            " Lunar ' Lunar'\n",
            " Calendar ' Calendar'\n",
            " interactive ' interactive'\n",
            ". '.'\n",
            " For ' For'\n",
            " instance ' instance'\n",
            ", ','\n",
            " you ' you'\n",
            " might ' might'\n",
            " script ' script'\n",
            " the ' the'\n",
            " calendar ' calendar'\n",
            " to ' to'\n",
            " display ' display'\n",
            " today ' today'\n",
            "'s \"'s\"\n",
            " date ' date'\n",
            " by ' by'\n",
            " default ' default'\n",
            ", ','\n",
            " and ' and'\n",
            " also ' also'\n",
            " allow ' allow'\n",
            " users ' users'\n",
            " to ' to'\n",
            " navigate ' navigate'\n",
            " through ' through'\n",
            " different ' different'\n",
            " phases ' phases'\n",
            " of ' of'\n",
            " the ' the'\n",
            " Moon ' Moon'\n",
            " via ' via'\n",
            " buttons ' buttons'\n",
            ", ','\n",
            " dropdown ' dropdown'\n",
            "s 's'\n",
            ", ','\n",
            " or ' or'\n",
            " other ' other'\n",
            " input ' input'\n",
            " elements ' elements'\n",
            ".\n",
            "\n",
            " '.\\n\\n'\n",
            "Here 'Here'\n",
            " is ' is'\n",
            " a ' a'\n",
            " brief ' brief'\n",
            " example ' example'\n",
            ":\n",
            "\n",
            " ':\\n\\n'\n",
            "``` '```'\n",
            "html 'html'\n",
            "\n",
            " '\\n'\n",
            "<! '<!'\n",
            "DOCTYPE 'DOCTYPE'\n",
            " html ' html'\n",
            ">\n",
            " '>\\n'\n",
            "<html '<html'\n",
            ">\n",
            "\n",
            " '>\\n\\n'\n",
            "<head '<head'\n",
            ">\n",
            " '>\\n'\n",
            "  ' '\n",
            " < ' <'\n",
            "style 'style'\n",
            ">\n",
            " '>\\n'\n",
            "    '   '\n",
            " /* ' /*'\n",
            " Add ' Add'\n",
            " your ' your'\n",
            " CSS ' CSS'\n",
            " styles ' styles'\n",
            " here ' here'\n",
            " */\n",
            " ' */\\n'\n",
            "  ' '\n",
            " </ ' </'\n",
            "style 'style'\n",
            ">\n",
            " '>\\n'\n",
            "</ '</'\n",
            "head 'head'\n",
            ">\n",
            "\n",
            " '>\\n\\n'\n",
            "<body '<body'\n",
            ">\n",
            " '>\\n'\n",
            "  ' '\n",
            " < ' <'\n",
            "div 'div'\n",
            " id ' id'\n",
            "=\" '=\"'\n",
            "calendar 'calendar'\n",
            "\"></ '\"></'\n",
            "div 'div'\n",
            ">\n",
            "\n",
            " '>\\n\\n'\n",
            "  ' '\n",
            " < ' <'\n",
            "script 'script'\n",
            " type ' type'\n",
            "=\" '=\"'\n",
            "text 'text'\n",
            "/javascript '/javascript'\n",
            "\">\n",
            " '\">\\n'\n",
            "    '   '\n",
            " // ' //'\n",
            " Create ' Create'\n",
            " JavaScript ' JavaScript'\n",
            " code ' code'\n",
            " to ' to'\n",
            " display ' display'\n",
            " the ' the'\n",
            " Lunar ' Lunar'\n",
            " Calendar ' Calendar'\n",
            " and ' and'\n",
            " interact ' interact'\n",
            " with ' with'\n",
            " it ' it'\n",
            ".\n",
            " '.\\n'\n",
            "  ' '\n",
            " </ ' </'\n",
            "script 'script'\n",
            ">\n",
            " '>\\n'\n",
            "</ '</'\n",
            "body 'body'\n",
            ">\n",
            "\n",
            " '>\\n\\n'\n",
            "</ '</'\n",
            "html 'html'\n",
            ">\n",
            " '>\\n'\n",
            "`` '``'\n",
            "`\n",
            "\n",
            " '`\\n\\n'\n",
            "In 'In'\n",
            " terms ' terms'\n",
            " of ' of'\n",
            " generating ' generating'\n",
            " accurate ' accurate'\n",
            " dates ' dates'\n",
            " for ' for'\n",
            " your ' your'\n",
            " Lunar ' Lunar'\n",
            " Calendar ' Calendar'\n",
            ", ','\n",
            " this ' this'\n",
            " will ' will'\n",
            " depend ' depend'\n",
            " on ' on'\n",
            " how ' how'\n",
            " you ' you'\n",
            " decide ' decide'\n",
            " to ' to'\n",
            " represent ' represent'\n",
            " the ' the'\n",
            " lunar ' lunar'\n",
            " phases ' phases'\n",
            ". '.'\n",
            " Typically ' Typically'\n",
            ", ','\n",
            " these ' these'\n",
            " are ' are'\n",
            " counted ' counted'\n",
            " in ' in'\n",
            " ' \" '\"\n",
            "mo 'mo'\n",
            "ons 'ons'\n",
            "' \"'\"\n",
            " ( ' ('\n",
            "approximately 'approximately'\n",
            "  ' '\n",
            "29 '29'\n",
            ". '.'\n",
            "5 '5'\n",
            " days ' days'\n",
            " each ' each'\n",
            "), '),'\n",
            " so ' so'\n",
            " you ' you'\n",
            " would ' would'\n",
            " need ' need'\n",
            " a ' a'\n",
            " method ' method'\n",
            " for ' for'\n",
            " converting ' converting'\n",
            " current ' current'\n",
            " date ' date'\n",
            " into ' into'\n",
            " which ' which'\n",
            " moon ' moon'\n",
            " phase ' phase'\n",
            " it ' it'\n",
            " falls ' falls'\n",
            " under ' under'\n",
            ".\n",
            "\n",
            " '.\\n\\n'\n",
            "I 'I'\n",
            " hope ' hope'\n",
            " that ' that'\n",
            " helps ' helps'\n",
            "! '!'\n",
            " Please ' Please'\n",
            " let ' let'\n",
            " me ' me'\n",
            " know ' know'\n",
            " if ' if'\n",
            " you ' you'\n",
            " have ' have'\n",
            " more ' more'\n",
            " questions ' questions'\n",
            "{'text': \"Using Javascript and CSS to create a beautiful lunar calendar, accurately displaying today's date, and all codes within the same HTML.\", 'files': []}\n",
            "Sure 'Sure'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ", ','\n",
            " I ' I'\n",
            " can ' can'\n",
            " help ' help'\n",
            " you ' you'\n",
            " with ' with'\n",
            " that ' that'\n",
            ".\n",
            "\n",
            " '.\\n\\n'\n",
            "Here 'Here'\n",
            " is ' is'\n",
            " an ' an'\n",
            " example ' example'\n",
            " of ' of'\n",
            " how ' how'\n",
            " you ' you'\n",
            " could ' could'\n",
            " structure ' structure'\n",
            " your ' your'\n",
            " code ' code'\n",
            " in ' in'\n",
            " HTML ' HTML'\n",
            ", ','\n",
            " JavaScript ' JavaScript'\n",
            " and ' and'\n",
            " CSS ' CSS'\n",
            ":\n",
            "\n",
            " ':\\n\\n'\n",
            "HTML 'HTML'\n",
            ":\n",
            " ':\\n'\n",
            "``` '```'\n",
            "html 'html'\n",
            "\n",
            " '\\n'\n",
            "<! '<!'\n",
            "DOCTYPE 'DOCTYPE'\n",
            " html ' html'\n",
            ">\n",
            " '>\\n'\n",
            "<html '<html'\n",
            ">\n",
            " '>\\n'\n",
            "<head '<head'\n",
            ">\n",
            " '>\\n'\n",
            "\t '\\t'\n",
            "<link '<link'\n",
            " rel ' rel'\n",
            "=\" '=\"'\n",
            "stylesheet 'stylesheet'\n",
            "\" '\"'\n",
            " type ' type'\n",
            "=\" '=\"'\n",
            "text 'text'\n",
            "/css '/css'\n",
            "\" '\"'\n",
            " href ' href'\n",
            "=\" '=\"'\n",
            "style 'style'\n",
            ".css '.css'\n",
            "\">\n",
            " '\">\\n'\n",
            "</ '</'\n",
            "head 'head'\n",
            ">\n",
            "\n",
            " '>\\n\\n'\n",
            "<body '<body'\n",
            " onload ' onload'\n",
            "=\" '=\"'\n",
            "load 'load'\n",
            "Data 'Data'\n",
            "()\">\n",
            " '()\">\\n'\n",
            "\t '\\t'\n",
            "<h '<h'\n",
            "1 '1'\n",
            ">L '>L'\n",
            "unar 'unar'\n",
            " Calendar ' Calendar'\n",
            "</ '</'\n",
            "h 'h'\n",
            "1 '1'\n",
            ">\n",
            " '>\\n'\n",
            "\t '\\t'\n",
            "<p '<p'\n",
            " id ' id'\n",
            "=\" '=\"'\n",
            "date 'date'\n",
            "\"></ '\"></'\n",
            "p 'p'\n",
            ">\n",
            " '>\\n'\n",
            "\t\n",
            " '\\t\\n'\n",
            "\t '\\t'\n",
            "<script '<script'\n",
            " src ' src'\n",
            "=\" '=\"'\n",
            "script 'script'\n",
            ".js '.js'\n",
            "\"></ '\"></'\n",
            "script 'script'\n",
            ">\n",
            " '>\\n'\n",
            "</ '</'\n",
            "body 'body'\n",
            ">\n",
            "\n",
            " '>\\n\\n'\n",
            "</ '</'\n",
            "html 'html'\n",
            ">\n",
            " '>\\n'\n",
            "`` '``'\n",
            "`\n",
            "\n",
            " '`\\n\\n'\n",
            "JavaScript 'JavaScript'\n",
            " ( ' ('\n",
            "Script 'Script'\n",
            ".js '.js'\n",
            "):\n",
            " '):\\n'\n",
            "``` '```'\n",
            "javascript 'javascript'\n",
            "\n",
            " '\\n'\n",
            "function 'function'\n",
            " loadData ' loadData'\n",
            "() '()'\n",
            " {\n",
            " ' {\\n'\n",
            "\tlet '\\tlet'\n",
            " today ' today'\n",
            " = ' ='\n",
            " new ' new'\n",
            " Date ' Date'\n",
            "();\n",
            " '();\\n'\n",
            "\tlet '\\tlet'\n",
            " lunar ' lunar'\n",
            "Month 'Month'\n",
            " = ' ='\n",
            " today ' today'\n",
            ".get '.get'\n",
            "UT 'UT'\n",
            "CD 'CD'\n",
            "ay 'ay'\n",
            "();\n",
            "\n",
            " '();\\n\\n'\n",
            "\tdocument '\\tdocument'\n",
            ".getElementById '.getElementById'\n",
            "(' \"('\"\n",
            "date 'date'\n",
            "'). \"').\"\n",
            "innerHTML 'innerHTML'\n",
            " = ' ='\n",
            " ' \" '\"\n",
            "Today 'Today'\n",
            " is ' is'\n",
            " ' \" '\"\n",
            " + ' +'\n",
            " today ' today'\n",
            ".toLocale '.toLocale'\n",
            "DateString 'DateString'\n",
            "() '()'\n",
            " + ' +'\n",
            " ', \" ',\"\n",
            " which ' which'\n",
            " corresponds ' corresponds'\n",
            " to ' to'\n",
            " Lunar ' Lunar'\n",
            " Month ' Month'\n",
            ": ':'\n",
            " ' \" '\"\n",
            " + ' +'\n",
            " lunar ' lunar'\n",
            "Month 'Month'\n",
            ";\n",
            " ';\\n'\n",
            "}\n",
            " '}\\n'\n",
            "`` '``'\n",
            "`\n",
            "\n",
            " '`\\n\\n'\n",
            "CSS 'CSS'\n",
            " ( ' ('\n",
            "Style 'Style'\n",
            ".css '.css'\n",
            "):\n",
            " '):\\n'\n",
            "``` '```'\n",
            "css 'css'\n",
            "\n",
            " '\\n'\n",
            "body 'body'\n",
            " {\n",
            " ' {\\n'\n",
            "\tfont '\\tfont'\n",
            "-family '-family'\n",
            ": ':'\n",
            " Arial ' Arial'\n",
            ", ','\n",
            " sans ' sans'\n",
            "-serif '-serif'\n",
            ";\n",
            " ';\\n'\n",
            "}\n",
            "\n",
            " '}\\n\\n'\n",
            "h 'h'\n",
            "1 '1'\n",
            " {\n",
            " ' {\\n'\n",
            "\ttext '\\ttext'\n",
            "-align '-align'\n",
            ": ':'\n",
            " center ' center'\n",
            ";\n",
            " ';\\n'\n",
            "}\n",
            "\n",
            " '}\\n\\n'\n",
            "p 'p'\n",
            " {\n",
            " ' {\\n'\n",
            "\ttext '\\ttext'\n",
            "-align '-align'\n",
            ": ':'\n",
            " center ' center'\n",
            ";\n",
            " ';\\n'\n",
            "\tfont '\\tfont'\n",
            "-size '-size'\n",
            ": ':'\n",
            "  ' '\n",
            "20 '20'\n",
            "px 'px'\n",
            ";\n",
            " ';\\n'\n",
            "\tcolor '\\tcolor'\n",
            ": ':'\n",
            " blue ' blue'\n",
            ";\n",
            " ';\\n'\n",
            "}\n",
            " '}\\n'\n",
            "`` '``'\n",
            "`\n",
            "\n",
            " '`\\n\\n'\n",
            "Please 'Please'\n",
            " make ' make'\n",
            " sure ' sure'\n",
            " that ' that'\n",
            " all ' all'\n",
            " three ' three'\n",
            " files ' files'\n",
            " ( ' ('\n",
            "HTML 'HTML'\n",
            ", ','\n",
            " JS ' JS'\n",
            " and ' and'\n",
            " CSS ' CSS'\n",
            ") ')'\n",
            " are ' are'\n",
            " saved ' saved'\n",
            " in ' in'\n",
            " the ' the'\n",
            " same ' same'\n",
            " directory ' directory'\n",
            " before ' before'\n",
            " running ' running'\n",
            " this ' this'\n",
            " code ' code'\n",
            ".\n",
            "\n",
            " '.\\n\\n'\n",
            "Let 'Let'\n",
            " me ' me'\n",
            " know ' know'\n",
            " if ' if'\n",
            " you ' you'\n",
            " need ' need'\n",
            " further ' further'\n",
            " help ' help'\n",
            ". '.'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =   32248.85 ms\n",
            "llama_print_timings:      sample time =     584.35 ms /   245 runs   (    2.39 ms per token,   419.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   50575.26 ms /   245 runs   (  206.43 ms per token,     4.84 tokens per second)\n",
            "llama_print_timings:       total time =   54856.46 ms /   246 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ''\n",
            "{'text': \"Using Javascript and CSS to create a beautiful lunar calendar, accurately displaying today's date, and all codes within the same HTML.\", 'files': []}\n",
            "Creating 'Creating'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " a ' a'\n",
            " lunar ' lunar'\n",
            " calendar ' calendar'\n",
            " using ' using'\n",
            " JavaScript ' JavaScript'\n",
            " ( ' ('\n",
            "JS 'JS'\n",
            ") ')'\n",
            " and ' and'\n",
            " Casc ' Casc'\n",
            "ading 'ading'\n",
            " Style ' Style'\n",
            " Sheets ' Sheets'\n",
            " ( ' ('\n",
            "CSS 'CSS'\n",
            "), '),'\n",
            " while ' while'\n",
            " also ' also'\n",
            " writing ' writing'\n",
            " all ' all'\n",
            " of ' of'\n",
            " the ' the'\n",
            " code ' code'\n",
            " inside ' inside'\n",
            " the ' the'\n",
            " same ' same'\n",
            " HTML ' HTML'\n",
            " file ' file'\n",
            " is ' is'\n",
            " certainly ' certainly'\n",
            " possible ' possible'\n",
            ". '.'\n",
            " Here ' Here'\n",
            " is ' is'\n",
            " an ' an'\n",
            " example ' example'\n",
            " of ' of'\n",
            " how ' how'\n",
            " you ' you'\n",
            " can ' can'\n",
            " begin ' begin'\n",
            " to ' to'\n",
            " structure ' structure'\n",
            " your ' your'\n",
            " HTML ' HTML'\n",
            " document ' document'\n",
            " with ' with'\n",
            " JS ' JS'\n",
            " and ' and'\n",
            " CSS ' CSS'\n",
            " included ' included'\n",
            ":\n",
            "\n",
            " ':\\n\\n'\n",
            "``` '```'\n",
            "HTML 'HTML'\n",
            "\n",
            " '\\n'\n",
            "<! '<!'\n",
            "DOCTYPE 'DOCTYPE'\n",
            " html ' html'\n",
            ">\n",
            " '>\\n'\n",
            "<html '<html'\n",
            ">\n",
            " '>\\n'\n",
            "    '   '\n",
            " < ' <'\n",
            "head 'head'\n",
            ">\n",
            " '>\\n'\n",
            "        '       '\n",
            " <!-- ' <!--'\n",
            " CSS ' CSS'\n",
            " Styles ' Styles'\n",
            " -->\n",
            " ' -->\\n'\n",
            "        '       '\n",
            " < ' <'\n",
            "style 'style'\n",
            ">\n",
            " '>\\n'\n",
            "            '           '\n",
            " /* ' /*'\n",
            " Your ' Your'\n",
            " styles ' styles'\n",
            " here ' here'\n",
            " */\n",
            " ' */\\n'\n",
            "        '       '\n",
            " </ ' </'\n",
            "style 'style'\n",
            ">\n",
            "\n",
            " '>\\n\\n'\n",
            "        '       '\n",
            " <!-- ' <!--'\n",
            " JavaScript ' JavaScript'\n",
            " Code ' Code'\n",
            " -->\n",
            " ' -->\\n'\n",
            "        '       '\n",
            " < ' <'\n",
            "script 'script'\n",
            ">\n",
            " '>\\n'\n",
            "            '           '\n",
            " // ' //'\n",
            " Your ' Your'\n",
            " code ' code'\n",
            " here ' here'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "from llama_cpp import Llama,LlamaRAMCache,LlamaDiskCache,LlamaTokenizer,LlamaState\n",
        "from llama_cpp.llama_speculative import LlamaPromptLookupDecoding\n",
        "from llama_cpp.llama_chat_format import Llava15ChatHandler\n",
        "import os,torch,json,shlex\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except :IN_COLAB=False\n",
        "Gbase=\"./generate/\"\n",
        "cache_dir=\"./hf/\"\n",
        "\n",
        "import torch\n",
        "from psutil import cpu_count\n",
        "import platform\n",
        "if torch.cuda.is_available():\n",
        "    n_gpu_layers=-1\n",
        "    n_threads=cpu_count()\n",
        "else :\n",
        "    n_gpu_layers=0\n",
        "    n_threads=cpu_count()\n",
        "\n",
        "if platform.machine()=='a0arch64' and not IN_COLAB:n_threads=4\n",
        "\n",
        "\n",
        "description =\"\"\"<div style=\"font-family: Arial, sans-serif; padding: 20px;\">\n",
        "\n",
        "This showcases the use of llama-cpp-python to load different versions of 4-bit and 8-bit models, as well as a simple chat interface created by Gradio. It can run on small computers or even mobile devices and produce satisfactory results. You are free to modify this code. I will continue to update these tools, first unlocking more possibilities to allow this tool to handle most common content, and then combining all of these possibilities with automation elements. Ultimately, it will evolve into a powerful tool that solves real-world problems effectively.\n",
        "\n",
        "這裡展示了使用llama-cpp-python來加載各種4位和8位模型的不同版本，以及由Gradio創建的簡單聊天界面。它可以在小型電腦甚至手機上運行，並能產生令人滿意的結果。您可以自由修改這段代碼。我將繼續更新這些工具，首先解鎖更多可能性，使此工具能夠處理大多數常見內容，然後將所有這些可能性與自動化元素結合在一起。最終，它將發展成一個有效解決現實問題的工具。\n",
        "  <h2>🔗My social media links❤️</h2>\n",
        "\n",
        "Follow <a href=\"https://www.facebook.com/braiml\"  ytarget=\"_blank\">🐍Brian's Page </a> if you want I share more tools .<br>\n",
        "Follow<a href=\"https://www.facebook.com/charactersAI\" target=\"_blank\">❤️Characters AI</a>\n",
        " if you want more  videos .\n",
        "<br>\n",
        "  <a href=\"https://www.facebook.com/brian.pyai\" target=\"_blank\"> 📘facebook.com/brian.pyai</a>\n",
        " <br>\n",
        "  <a href=\"https://www.facebook.com/braiml\" target=\"_blank\">🐍Brian's Page </a>\n",
        "<br>\n",
        "\n",
        "  <a href=\"https://www.facebook.com/lovelyai999\" target=\"_blank\">🥰AI Hot Shorts </a>\n",
        "\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "\"\"\"\n",
        "import base64\n",
        "import io\n",
        "def image_to_base64_data_uri(file_path):\n",
        "    i=Image.open(file_path)\n",
        "    i.resize((256,256))\n",
        "    img_byte_arr = io.BytesIO()\n",
        "    i.save(img_byte_arr, format='PNG')\n",
        "    base64_data = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
        "    return f\"data:image/png;base64,{base64_data}\"\n",
        "\n",
        "modelsPath=\"./\"\n",
        "\n",
        "modelsPaths= [\"mradermacher/llava-v1.6-mistral-7b-GGUF/llava-v1.6-mistral-7b.Q4_K_M.gguf\",\"SanctumAI/Phi-3-mini-4k-instruct-GGUF/phi-3-mini-4k-instruct.Q4_K_M.gguf\",\"MaziyarPanahi/WizardLM-2-7B-GGUF/WizardLM-2-7B.Q4_K_M.gguf\",\"SanctumAI/Phi-3-mini-4k-instruct-GGUF/phi-3-mini-4k-instruct.Q8_0.gguf\",\"MaziyarPanahi/WizardLM-2-7B-GGUF/WizardLM-2-7B.Q8_0.gguf\",\"FaradayDotDev/llama-3-8b-Instruct-GGUF/llama-3-8b-Instruct.Q4_K_M.gguf\",\"seyf1elislam/llama-3-neural-chat-v1-8b-GGUF/llama-3-neural-chat-v1-8b.Q4_K_M.gguf\",\"seyf1elislam/llama-3-neural-chat-v1-8b-GGUF/llama-3-neural-chat-v1-8b.Q8_0.gguf\",\"Quant-Cartel/Llama-3-8B-Instruct-DADA-iMat-GGUF/Llama-3-8B-Instruct-DADA-iMat-IQ4_XS.gguf\",\"Quant-Cartel/Llama-3-8B-Instruct-DADA-iMat-GGUF/Llama-3-8B-Instruct-DADA-iMat-Q8_0.gguf\",\"3thn/dolphin-2.9-llama3-8b-GGUF/dolphin-2.9-llama3-8b.Q4_K_M.gguf\",\"3thn/dolphin-2.9-llama3-8b-GGUF/dolphin-2.9-llama3-8b.Q8_0.gguf\",\"PawanKrd/Meta-Llama-3-70B-Instruct-GGUF/llama-3-70b-instruct.Q3_K_M.gguf\",\"twodgirl/zephyr-beta-wizardLM-2-merge-7B-Q6_K-GGUF/zephyr-beta-wizardlm-2-merge-7b.Q6_K.gguf\",\"MaziyarPanahi/WizardLM-2-8x22B-GGUF/WizardLM-2-8x22B.IQ1_M.gguf\",\"TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/dolphin-2.7-mixtral-8x7b.Q2_K.gguf\",\"TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/dolphin-2.7-mixtral-8x7b.Q4_K_M.gguf\",\"mradermacher/Starling-LM-alpha-8x7B-MoE-GGUF/Starling-LM-alpha-8x7B-MoE.Q4_K_M.gguf\",\"MaziyarPanahi/Qwen1.5-8x7b-v0.1-GGUF/Qwen1.5-8x7b-v0.1.Q4_K_M.gguf\",\"TheBloke/firefly-mixtral-8x7b-GGUF/firefly-mixtral-8x7b.Q4_K_M.gguf\",\"TheBloke/openbuddy-mixtral-8x7b-v15.1-GGUF/openbuddy-mixtral-8x7b-v15.1.Q4_K_M.gguf\",\"Quant-Cartel/Cerebrum-1.0-8x7b-iMat-GGUF/Cerebrum-1.0-8x7b-iMat-Q4_K_M.gguf\",\"MaziyarPanahi/Experiment26-7B-GGUF/Experiment26-7B.Q4_K_M.gguf\",\"dagbs/dolphin-2.8-experiment26-7b-preview-GGUF/dolphin-2.8-experiment26-7b.Q4_K_M.gguf\",\"ggml-org/gemma-1.1-2b-it-Q4_K_M-GGUF/gemma-1.1-2b-it.Q4_K_M.gguf\",\"chenhunghan/TAIDE-LX-7B-Chat-GGUF/taide-lx-7b-chat.q4_k_m.gguf\",\"chenhunghan/TAIDE-LX-7B-Chat-GGUF/taide-lx-7b-chat.q8_0.gguf\",\"ggml-org/gemma-1.1-7b-it-Q4_K_M-GGUF/gemma-1.1-7b-it.Q4_K_M.gguf\",\"ggml-org/gemma-1.1-2b-it-Q8_0-GGUF/gemma-1.1-2b-it.Q8_0.gguf\",\"ggml-org/gemma-1.1-7b-it-Q8_0-GGUF/gemma-1.1-7b-it.Q8_0.gguf\",\"pi-null-mezon/openchat-3.5-0106-gemma-GGUF/ggml-model-Q8_0.gguf\",\"pi-null-mezon/openchat-3.5-0106-gemma-GGUF/ggml-model-Q4_K_M.gguf\",\"mlabonne/Gemmalpaca-2B-GGUF/gemmalpaca-2b.Q4_K_M.gguf\",\"LoneStriker/gemma-2b-GGUF/gemma-2b-Q4_K_M.gguf\",\"LoneStriker/gemma-2b-it-GGUF/gemma-2b-it-Q4_K_M.gguf\",\"LoneStriker/gemma-7b-GGUF/gemma-7b-Q4_K_M.gguf\",\"LoneStriker/gemma-7b-it-GGUF/gemma-7b-it-Q4_K_M.gguf\",\"mlabonne/Gemmalpaca-2B-GGUF/gemmalpaca-2b.Q4_K_M.gguf\",\"LoneStriker/OrcaGemma-2B-GGUF/OrcaGemma-2B-Q4_K_M.gguf\",\"rombodawg/EveryoneLLM-7b-Gemma-Base-GGUF/EveryoneLLM-7b-Gemma-Base-q6_k.gguf\",\"LoneStriker/openbuddy-gemma-7b-v19.1-4k-GGUF/openbuddy-gemma-7b-v19.1-4k-Q4_K_M.gguf\",\"LoneStriker/Gemmalpaca-7B-GGUF/Gemmalpaca-7B-Q4_K_M.gguf\", \"LoneStriker/zephyr-7b-gemma-v0.1-GGUF/zephyr-7b-gemma-v0.1-Q4_K_M.gguf\" ,\"Lewdiculous/firefly-gemma-7b-GGUF-IQ-Imatrix/firefly-gemma-7b-Q4_K_S-imatrix.gguf\"]\n",
        "\n",
        "\n",
        "\n",
        "model_id=\"SanctumAI/Phi-3-mini-4k-instruct-GGUF/phi-3-mini-4k-instruct.Q8_0.gguf\" #@param    [\"mradermacher/llava-v1.6-mistral-7b-GGUF/llava-v1.6-mistral-7b.Q4_K_M.gguf\",\"SanctumAI/Phi-3-mini-4k-instruct-GGUF/phi-3-mini-4k-instruct.Q4_K_M.gguf\",\"MaziyarPanahi/WizardLM-2-7B-GGUF/WizardLM-2-7B.Q4_K_M.gguf\",\"SanctumAI/Phi-3-mini-4k-instruct-GGUF/phi-3-mini-4k-instruct.Q8_0.gguf\",\"MaziyarPanahi/WizardLM-2-7B-GGUF/WizardLM-2-7B.Q8_0.gguf\",\"FaradayDotDev/llama-3-8b-Instruct-GGUF/llama-3-8b-Instruct.Q4_K_M.gguf\",\"seyf1elislam/llama-3-neural-chat-v1-8b-GGUF/llama-3-neural-chat-v1-8b.Q4_K_M.gguf\",\"seyf1elislam/llama-3-neural-chat-v1-8b-GGUF/llama-3-neural-chat-v1-8b.Q8_0.gguf\",\"Quant-Cartel/Llama-3-8B-Instruct-DADA-iMat-GGUF/Llama-3-8B-Instruct-DADA-iMat-IQ4_XS.gguf\",\"Quant-Cartel/Llama-3-8B-Instruct-DADA-iMat-GGUF/Llama-3-8B-Instruct-DADA-iMat-Q8_0.gguf\",\"3thn/dolphin-2.9-llama3-8b-GGUF/dolphin-2.9-llama3-8b.Q4_K_M.gguf\",\"3thn/dolphin-2.9-llama3-8b-GGUF/dolphin-2.9-llama3-8b.Q8_0.gguf\",\"PawanKrd/Meta-Llama-3-70B-Instruct-GGUF/llama-3-70b-instruct.Q3_K_M.gguf\",\"twodgirl/zephyr-beta-wizardLM-2-merge-7B-Q6_K-GGUF/zephyr-beta-wizardlm-2-merge-7b.Q6_K.gguf\",\"MaziyarPanahi/WizardLM-2-8x22B-GGUF/WizardLM-2-8x22B.IQ1_M.gguf\",\"TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/dolphin-2.7-mixtral-8x7b.Q2_K.gguf\",\"TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/dolphin-2.7-mixtral-8x7b.Q4_K_M.gguf\",\"mradermacher/Starling-LM-alpha-8x7B-MoE-GGUF/Starling-LM-alpha-8x7B-MoE.Q4_K_M.gguf\",\"MaziyarPanahi/Qwen1.5-8x7b-v0.1-GGUF/Qwen1.5-8x7b-v0.1.Q4_K_M.gguf\",\"TheBloke/firefly-mixtral-8x7b-GGUF/firefly-mixtral-8x7b.Q4_K_M.gguf\",\"TheBloke/openbuddy-mixtral-8x7b-v15.1-GGUF/openbuddy-mixtral-8x7b-v15.1.Q4_K_M.gguf\",\"Quant-Cartel/Cerebrum-1.0-8x7b-iMat-GGUF/Cerebrum-1.0-8x7b-iMat-Q4_K_M.gguf\",\"MaziyarPanahi/Experiment26-7B-GGUF/Experiment26-7B.Q4_K_M.gguf\",\"dagbs/dolphin-2.8-experiment26-7b-preview-GGUF/dolphin-2.8-experiment26-7b.Q4_K_M.gguf\",\"ggml-org/gemma-1.1-2b-it-Q4_K_M-GGUF/gemma-1.1-2b-it.Q4_K_M.gguf\",\"chenhunghan/TAIDE-LX-7B-Chat-GGUF/taide-lx-7b-chat.q4_k_m.gguf\",\"chenhunghan/TAIDE-LX-7B-Chat-GGUF/taide-lx-7b-chat.q8_0.gguf\",\"ggml-org/gemma-1.1-7b-it-Q4_K_M-GGUF/gemma-1.1-7b-it.Q4_K_M.gguf\",\"ggml-org/gemma-1.1-2b-it-Q8_0-GGUF/gemma-1.1-2b-it.Q8_0.gguf\",\"ggml-org/gemma-1.1-7b-it-Q8_0-GGUF/gemma-1.1-7b-it.Q8_0.gguf\",\"pi-null-mezon/openchat-3.5-0106-gemma-GGUF/ggml-model-Q8_0.gguf\",\"pi-null-mezon/openchat-3.5-0106-gemma-GGUF/ggml-model-Q4_K_M.gguf\",\"mlabonne/Gemmalpaca-2B-GGUF/gemmalpaca-2b.Q4_K_M.gguf\",\"LoneStriker/gemma-2b-GGUF/gemma-2b-Q4_K_M.gguf\",\"LoneStriker/gemma-2b-it-GGUF/gemma-2b-it-Q4_K_M.gguf\",\"LoneStriker/gemma-7b-GGUF/gemma-7b-Q4_K_M.gguf\",\"LoneStriker/gemma-7b-it-GGUF/gemma-7b-it-Q4_K_M.gguf\",\"mlabonne/Gemmalpaca-2B-GGUF/gemmalpaca-2b.Q4_K_M.gguf\",\"LoneStriker/OrcaGemma-2B-GGUF/OrcaGemma-2B-Q4_K_M.gguf\",\"rombodawg/EveryoneLLM-7b-Gemma-Base-GGUF/EveryoneLLM-7b-Gemma-Base-q6_k.gguf\",\"LoneStriker/openbuddy-gemma-7b-v19.1-4k-GGUF/openbuddy-gemma-7b-v19.1-4k-Q4_K_M.gguf\",\"LoneStriker/Gemmalpaca-7B-GGUF/Gemmalpaca-7B-Q4_K_M.gguf\", \"LoneStriker/zephyr-7b-gemma-v0.1-GGUF/zephyr-7b-gemma-v0.1-Q4_K_M.gguf\" ,\"Lewdiculous/firefly-gemma-7b-GGUF-IQ-Imatrix/firefly-gemma-7b-Q4_K_S-imatrix.gguf\"]\n",
        "def selectPath(paths=modelsPaths):\n",
        "    #return \"gemma-openchat7v-model-Q4_K_M.gguf\"\n",
        "    ls=paths\n",
        "    #c='termux-dialog radio -v \"%s\" -t \"Select model\"' % \",\".join(ls)\n",
        "    #v=eval(os.popen(c).read())[\"text\"]\n",
        "    for i,t in enumerate(ls):print (\"%s) %s\" % (i ,t) )\n",
        "    print (\"input the number :\")\n",
        "    v=ls[int(input())]\n",
        "\n",
        "    return v\n",
        "if not IN_COLAB:\n",
        "    model_id=selectPath()\n",
        "def downHgFile(url,targetDir=modelsPath):\n",
        "    fileName=Path (model_id ).name\n",
        "    repo =model_id[:-len(fileName)-1]\n",
        "    print(fileName,repo)\n",
        "    fileExists=os.path.exists(os.path.join(targetDir,fileName))\n",
        "\n",
        "    print(repo,fileName,fileExists )\n",
        "    if not fileExists:\n",
        "        print (\"Downloading file :\")\n",
        "        hf_hub_download(repo ,filename=fileName,local_dir=targetDir,local_dir_use_symlinks=False)\n",
        "max_tokens=4096 # @param {type:\"integer\",min:10, max:8192}\n",
        "n_ctx=4096 # @param {type:\"integer\",min:10, max:8192}\n",
        "downHgFile(model_id )\n",
        "#hf_hub_download(\"lovelyai999/temp\" ,filename=\"mistral_7b_mmproj-v1_5_Q4_1.gguf\",local_dir=\"./\",local_dir_use_symlinks=False)\n",
        "modelPath=os.path.join(modelsPath,Path(model_id).name)\n",
        "if (\"8x\" in model_id or \"70b\" in model_id) and torch.cuda.is_available():\n",
        "    n_gpu_layers=16\n",
        "    if  \"70b\" in model_id:\n",
        "        n_gpu_layers=24\n",
        "    n_threads=4\n",
        "if model_id==\"mradermacher/llava-v1.6-mistral-7b-GGUF/llava-v1.6-mistral-7b.Q4_K_M.gguf\":\n",
        "    if not os.path.exists(\"mistral_7b_mmproj-v1_5_Q4_1.gguf\"):hf_hub_download(\"lovelyai999/temp\" ,filename=\"mistral_7b_mmproj-v1_5_Q4_1.gguf\",local_dir=\"./\",local_dir_use_symlinks=False)\n",
        "    chat_handler = Llava15ChatHandler(clip_model_path=\"mistral_7b_mmproj-v1_5_Q4_1.gguf\",verbose=True)\n",
        "    model = Llama(modelPath,n_gpu_layers=n_gpu_layers,n_threads=n_threads,max_tokens=4096,logits_all=True,n_ctx=n_ctx,chat_handler=chat_handler)\n",
        "else:\n",
        "    model = Llama(modelPath,n_gpu_layers=n_gpu_layers,n_threads=n_threads,max_tokens=4096,logits_all=True,n_ctx=n_ctx)\n",
        "#draft_model=LlamaPromptLookupDecoding(num_pred_tokens=10) )\n",
        "\n",
        "tokenizer = model.tokenize\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "from threading import Thread\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "partial_message = \"\"\n",
        "\n",
        "def predict(message, history,top_k=300, top_p=0.95, temp=0.85, repeat_penalty=1.1,max_tokens=max_tokens):\n",
        "    global partial_message,model_id\n",
        "    try :messageT=message[\"text\"]\n",
        "    except :messageT=message\n",
        "    global model_id\n",
        "    if \"phi-3-\" in model_id:\n",
        "        prompt=f\"<|user|>{messageT}<|end|><|assistant|>\"\n",
        "    else:\n",
        "        prompt=f\"\"\"### System:\n",
        "You are a professional private assistant.\n",
        "### User:\n",
        "{messageT}\n",
        "###  Response:\n",
        "\n",
        "\"\"\"\n",
        "    prompt_=f\"\"\"\n",
        "###Below is an instruction that describes my question or task.\n",
        "Write a response that appropriately completes the request:\n",
        "{messageT}\n",
        "### Response :\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    print (message)\n",
        "    #model_inputs = tokenizer(prompt.encode(\"utf-8\"))\n",
        "    #generate_kwargs = dict(top_k=top_k, top_p=top_p, temp=temp, repeat_penalty=repeat_penalty)\n",
        "    stop= [\"<|end|>\" ,\"<|end_of_text|>\"  ]\n",
        "    if model_id in [\"FaradayDotDev/llama-3-8b-Instruct-GGUF/llama-3-8b-Instruct.Q4_K_M.gguf\",\"l3utterfly/llama-3-8b-Instruct-gguf/llama-3-8b-Instruct-Q4_K.gguf\",\"l3utterfly/llama-3-8b-Instruct-gguf/llama-3-8b-Instruct-Q8_0.gguf\",\"PawanKrd/Meta-Llama-3-70B-Instruct-GGUFFaradayDotDev/llama-3-8b-Instruct-GGUF/llama-3-70b-instruct.Q2_K.gguf\",\"PawanKrd/Meta-Llama-3-70B-Instruct-GGUF/llama-3-70b-instruct.Q3_K_M.gguf\"]:\n",
        "        stop=[\"### Below\",\".\\n\\n\",\"assistant\\n\\n\",\"!\\n\\n\",\"<|end|>\" ,\"<|end_of_text|>\" ]\n",
        "    generate_kwargs=dict (suffix=None, max_tokens=max_tokens, temperature=temp, top_p=top_p, min_p=0.05, typical_p=1.0, logprobs=None, echo=False, stop=stop, frequency_penalty=0,presence_penalty=0.0, repeat_penalty=1.1, top_k=top_k, stream=True , seed=None, tfs_z=1.0, mirostat_mode=0, mirostat_tau=5.0, mirostat_eta=0.1, model=None, stopping_criteria=None, logits_processor=None, grammar=None, logit_bias=None)\n",
        "\n",
        "\n",
        "    partial_message = \"\"\n",
        "    if isinstance(message,dict) and message[\"files\"] and message[\"files\"][0][\"path\"] and message[\"files\"][0]['mime_type'].startswith(\"image\"):\n",
        "        messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an assistant who perfectly describes images.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\":message[\"files\"][0][\"path\"]}},\n",
        "                {\"type\" : \"text\", \"text\": messageT}\n",
        "            ]\n",
        "        }]\n",
        "        outputs =model.create_completion(json.dumps (messages),**generate_kwargs)\n",
        "    else:\n",
        "        outputs =model.create_completion(prompt ,**generate_kwargs)\n",
        "\n",
        "\n",
        "    for chunk in outputs:\n",
        "        #print (chunk )\n",
        "        content = chunk[\"choices\"][0][\"text\"]\n",
        "        #print(content,repr(content ))\n",
        "        if content:\n",
        "            partial_message+=content\n",
        "            yield partial_message\n",
        "    \"\"\"\n",
        "    for new_token in model.generate(model_inputs,**generate_kwargs):\n",
        "            #print (new_token)\n",
        "            if new_token in (213,7221,1):break\n",
        "            s=model.detokenize([new_token])\n",
        "            #print (s)\n",
        "            if isinstance(s,bytes):\n",
        "                try:partial_message += s.decode(\"utf-8\")\n",
        "                except :break\n",
        "            yield partial_message\n",
        "        \"\"\"\n",
        "\n",
        "chatbot = gr.Chatbot(likeable=True,show_copy_button=True)\n",
        "textbox = gr.Textbox (show_copy_button=True)\n",
        "\n",
        "user=\"brian\" #@param {type:\"string\"}\n",
        "password=\"pwd\" #@param {type:\"string\"}\n",
        "auth=(user,password)\n",
        "\n",
        "gr.ChatInterface(predict,chatbot=chatbot,stop_btn=\"Stop\" ,retry_btn=\"Retry\",concurrency_limit=1,description=description,\n",
        "additional_inputs=[gr.Number(value=100,minimum =0,maximum =1000,precision=0,show_label=True ,label=\"Topic K\"),\n",
        "gr.Number(value=0.85,minimum =0,maximum =1,precision=3,show_label=True ,label=\"Topic P\"),\n",
        "gr.Number(value=0.85,minimum =0,maximum =1,precision=3,show_label=True ,label=\"Temperature\"),gr.Number(value=1.1,minimum =1,maximum =3,precision=3,show_label=True ,label=\"Repeat penalty\") ,gr.Number(value=4096,minimum =0,maximum =8192,precision=0,show_label=True ,label=\"max_tokens\") ],multimodal=True ).launch(debug=True,share=True ,inline=False,auth=auth )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNzWGY8dUcXr6iXw0IaoPah",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}