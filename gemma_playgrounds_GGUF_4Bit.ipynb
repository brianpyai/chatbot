{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianpyai/chatbot/blob/main/gemma_playgrounds_GGUF_4Bit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-czlAOa2dN4g",
        "outputId": "d03d70a3-79ce-468e-f6aa-4c1c5c568a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio==4.22.0\n",
            "  Downloading gradio-4.22.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.22.0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (4.2.2)\n",
            "Collecting fastapi (from gradio==4.22.0)\n",
            "  Downloading fastapi-0.110.2-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==4.22.0)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.13.0 (from gradio==4.22.0)\n",
            "  Downloading gradio_client-0.13.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio==4.22.0)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio==4.22.0)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (2.7.0)\n",
            "Collecting pydub (from gradio==4.22.0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio==4.22.0)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio==4.22.0)\n",
            "  Downloading ruff-0.4.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==4.22.0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.22.0)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (0.9.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.22.0) (4.11.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==4.22.0)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.13.0->gradio==4.22.0) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.13.0->gradio==4.22.0)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.22.0) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.22.0) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.22.0) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.22.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.22.0) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio==4.22.0)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.22.0) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.22.0) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio==4.22.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.22.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.22.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.22.0) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.22.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.22.0) (2.18.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.22.0) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio==4.22.0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio==4.22.0)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.22.0) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio==4.22.0)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.22.0) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.22.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.22.0) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio==4.22.0) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.22.0) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=b8cad35b9338ecb046e66a8b1b6f81fb7761eecc53db606097e41733fc8a3019\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, colorama, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 colorama-0.4.6 fastapi-0.110.2 ffmpy-0.3.2 gradio-4.22.0 gradio-client-0.13.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.1 pydub-0.25.1 python-multipart-0.0.9 ruff-0.4.2 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 uvicorn-0.29.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install gradio==4.22.0 transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ8HCwYutHId",
        "outputId": "0b35cd09-9ef5-4f01-f3e6-fc6b537d2344"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\n",
        "#@title Built llama-cpp-python with BLAS or CUDA automatically, wait for few minutes .\n",
        "import os,torch\n",
        "\n",
        "\n",
        "if torch.cuda.is_available ():\n",
        "    cmd='CMAKE_ARGS=\"%s\" pip install llama-cpp-python==0.2.62' % \"-DLLAMA_CUBLAS=on\"\n",
        "else:\n",
        "    cmd='CMAKE_ARGS=\"%s\" pip install llama-cpp-python==0.2.62' % \"-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS\"\n",
        "\n",
        "os.system (cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 253,
          "referenced_widgets": [
            "cc1cbff218154d019b903f815856fe44",
            "a23a08f936da48088f06610469159420",
            "ee6e62eb1b294334a83722ece56c0556",
            "4c1edaf855444fe49d3b8c962b88e745",
            "ddc6f8ad6c7b4efca113a48952b82d3d",
            "c73f60b02edd4aed8abc130617ab6362",
            "24d3bef8015e4a19bfb8e23d46ed621d",
            "ef71584f1c9c40a1adcb1b0166ad17ea",
            "e0592ff1b391417e83c262a17fe46666",
            "5dc794c447fe416486926f593478359d",
            "46a1c615f2c14d489dc906b4cd9258fa"
          ]
        },
        "id": "XOxIBjXDN2ee",
        "outputId": "f68e4376-437b-48d0-dd6f-d969575ce86b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phi-3-mini-4k-instruct.Q8_0.gguf SanctumAI/Phi-3-mini-4k-instruct-GGUF\n",
            "SanctumAI/Phi-3-mini-4k-instruct-GGUF phi-3-mini-4k-instruct.Q8_0.gguf False\n",
            "Downloading file :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "phi-3-mini-4k-instruct.Q8_0.gguf:   0%|          | 0.00/4.06G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc1cbff218154d019b903f815856fe44"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "from llama_cpp import Llama,LlamaRAMCache,LlamaDiskCache,LlamaTokenizer,LlamaState\n",
        "from llama_cpp.llama_speculative import LlamaPromptLookupDecoding\n",
        "from llama_cpp.llama_chat_format import Llava15ChatHandler\n",
        "import os,torch,json,shlex\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except :IN_COLAB=False\n",
        "Gbase=\"./generate/\"\n",
        "cache_dir=\"./hf/\"\n",
        "\n",
        "import torch\n",
        "from psutil import cpu_count\n",
        "import platform\n",
        "if torch.cuda.is_available():\n",
        "    n_gpu_layers=-1\n",
        "    n_threads=cpu_count()\n",
        "else :\n",
        "    n_gpu_layers=0\n",
        "    n_threads=cpu_count()\n",
        "\n",
        "if platform.machine()=='aarch64' and not IN_COLAB:n_threads=4\n",
        "\n",
        "\n",
        "description =\"\"\"<div style=\"font-family: Arial, sans-serif; padding: 20px;\">\n",
        "\n",
        "This showcases the use of llama-cpp-python to load different versions of 4-bit and 8-bit models, as well as a simple chat interface created by Gradio. It can run on small computers or even mobile devices and produce satisfactory results. You are free to modify this code. I will continue to update these tools, first unlocking more possibilities to allow this tool to handle most common content, and then combining all of these possibilities with automation elements. Ultimately, it will evolve into a powerful tool that solves real-world problems effectively.\n",
        "\n",
        "ÈÄôË£°Â±ïÁ§∫‰∫Ü‰ΩøÁî®llama-cpp-python‰æÜÂä†ËºâÂêÑÁ®Æ4‰ΩçÂíå8‰ΩçÊ®°ÂûãÁöÑ‰∏çÂêåÁâàÊú¨Ôºå‰ª•ÂèäÁî±GradioÂâµÂª∫ÁöÑÁ∞°ÂñÆËÅäÂ§©ÁïåÈù¢„ÄÇÂÆÉÂèØ‰ª•Âú®Â∞èÂûãÈõªËÖ¶ÁîöËá≥ÊâãÊ©ü‰∏äÈÅãË°åÔºå‰∏¶ËÉΩÁî¢Áîü‰ª§‰∫∫ÊªøÊÑèÁöÑÁµêÊûú„ÄÇÊÇ®ÂèØ‰ª•Ëá™Áî±‰øÆÊîπÈÄôÊÆµ‰ª£Á¢º„ÄÇÊàëÂ∞áÁπºÁ∫åÊõ¥Êñ∞ÈÄô‰∫õÂ∑•ÂÖ∑ÔºåÈ¶ñÂÖàËß£ÈéñÊõ¥Â§öÂèØËÉΩÊÄßÔºå‰ΩøÊ≠§Â∑•ÂÖ∑ËÉΩÂ§†ËôïÁêÜÂ§ßÂ§öÊï∏Â∏∏Ë¶ãÂÖßÂÆπÔºåÁÑ∂ÂæåÂ∞áÊâÄÊúâÈÄô‰∫õÂèØËÉΩÊÄßËàáËá™ÂãïÂåñÂÖÉÁ¥†ÁµêÂêàÂú®‰∏ÄËµ∑„ÄÇÊúÄÁµÇÔºåÂÆÉÂ∞áÁôºÂ±ïÊàê‰∏ÄÂÄãÊúâÊïàËß£Ê±∫ÁèæÂØ¶ÂïèÈ°åÁöÑÂ∑•ÂÖ∑„ÄÇ\n",
        "  <h2>üîóMy social media links‚ù§Ô∏è</h2>\n",
        "\n",
        "Follow <a href=\"https://www.facebook.com/braiml\"  ytarget=\"_blank\">üêçBrian's Page </a> if you want I share more tools .<br>\n",
        "Follow<a href=\"https://www.facebook.com/charactersAI\" target=\"_blank\">‚ù§Ô∏èCharacters AI</a>\n",
        " if you want more  videos .\n",
        "<br>\n",
        "  <a href=\"https://www.facebook.com/brian.pyai\" target=\"_blank\"> üìòfacebook.com/brian.pyai</a>\n",
        " <br>\n",
        "  <a href=\"https://www.facebook.com/braiml\" target=\"_blank\">üêçBrian's Page </a>\n",
        "<br>\n",
        "\n",
        "  <a href=\"https://www.facebook.com/lovelyai999\" target=\"_blank\">ü•∞AI Hot Shorts </a>\n",
        "\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "\"\"\"\n",
        "import base64\n",
        "import io\n",
        "def image_to_base64_data_uri(file_path):\n",
        "    i=Image.open(file_path)\n",
        "    i.resize((256,256))\n",
        "    img_byte_arr = io.BytesIO()\n",
        "    i.save(img_byte_arr, format='PNG')\n",
        "    base64_data = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
        "    return f\"data:image/png;base64,{base64_data}\"\n",
        "\n",
        "modelsPath=\"./\"\n",
        "\n",
        "modelsPaths= [\"mradermacher/llava-v1.6-mistral-7b-GGUF/llava-v1.6-mistral-7b.Q4_K_M.gguf\",\"RDson/llava-llama-3-8b-v1_1-GGUF/llava-llama-3-8b-v1_1-Q8_0.gguf\",\"IHaveNoClueAndIMustPost/Llama-3-11.5B-Instruct-v2_GGUF/Replete-AI_Llama-3-11.5B-Instruct-v2-Q6_K.gguf\",\"PrunaAI/Llama-3-16B-GGUF-smashed/Llama-3-16B.Q8_0.gguf\",\"PrunaAI/Llama-3-16B-GGUF-smashed/Llama-3-16B.Q4_K_M.gguf\",\n",
        "\"SanctumAI/Phi-3-mini-4k-instruct-GGUF/phi-3-mini-4k-instruct.Q4_K_M.gguf\",\"mradermacher/Llama3-8B-DPO-uncensored-GGUF/Llama3-8B-DPO-uncensored.Q8_0.gguf\",\"mradermacher/Llama3-Inst-8B-DPO-Ultrafeedback-GGUF/Llama3-Inst-8B-DPO-Ultrafeedback.Q8_0.gguf\",\"DavidAU/Llama3-8B-OpenHermes-DPO-Q8_0-GGUF/llama3-8b-openhermes-dpo.Q8_0.gguf\",\"LoneStriker/OrpoLlama-3-8B-GGUF/OrpoLlama-3-8B-Q8_0.gguf\",\"MaziyarPanahi/WizardLM-2-7B-GGUF/WizardLM-2-7B.Q4_K_M.gguf\",\"SanctumAI/Phi-3-mini-4k-instruct-GGUF/phi-3-mini-4k-instruct.Q8_0.gguf\",\"MaziyarPanahi/WizardLM-2-7B-GGUF/WizardLM-2-7B.Q8_0.gguf\",\"FaradayDotDev/llama-3-8b-Instruct-GGUF/llama-3-8b-Instruct.Q4_K_M.gguf\",\"seyf1elislam/llama-3-neural-chat-v1-8b-GGUF/llama-3-neural-chat-v1-8b.Q4_K_M.gguf\",\"seyf1elislam/llama-3-neural-chat-v1-8b-GGUF/llama-3-neural-chat-v1-8b.Q8_0.gguf\",\"Quant-Cartel/Llama-3-8B-Instruct-DADA-iMat-GGUF/Llama-3-8B-Instruct-DADA-iMat-IQ4_XS.gguf\",\"Quant-Cartel/Llama-3-8B-Instruct-DADA-iMat-GGUF/Llama-3-8B-Instruct-DADA-iMat-Q8_0.gguf\",\"3thn/dolphin-2.9-llama3-8b-GGUF/dolphin-2.9-llama3-8b.Q4_K_M.gguf\",\"3thn/dolphin-2.9-llama3-8b-GGUF/dolphin-2.9-llama3-8b.Q8_0.gguf\",\"PawanKrd/Meta-Llama-3-70B-Instruct-GGUF/llama-3-70b-instruct.Q3_K_M.gguf\",\"twodgirl/zephyr-beta-wizardLM-2-merge-7B-Q6_K-GGUF/zephyr-beta-wizardlm-2-merge-7b.Q6_K.gguf\",\"MaziyarPanahi/WizardLM-2-8x22B-GGUF/WizardLM-2-8x22B.IQ1_M.gguf\",\"TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/dolphin-2.7-mixtral-8x7b.Q2_K.gguf\",\"TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/dolphin-2.7-mixtral-8x7b.Q4_K_M.gguf\",\"mradermacher/Starling-LM-alpha-8x7B-MoE-GGUF/Starling-LM-alpha-8x7B-MoE.Q4_K_M.gguf\",\"MaziyarPanahi/Qwen1.5-8x7b-v0.1-GGUF/Qwen1.5-8x7b-v0.1.Q4_K_M.gguf\",\"TheBloke/firefly-mixtral-8x7b-GGUF/firefly-mixtral-8x7b.Q4_K_M.gguf\",\"TheBloke/openbuddy-mixtral-8x7b-v15.1-GGUF/openbuddy-mixtral-8x7b-v15.1.Q4_K_M.gguf\",\"Quant-Cartel/Cerebrum-1.0-8x7b-iMat-GGUF/Cerebrum-1.0-8x7b-iMat-Q4_K_M.gguf\",\"MaziyarPanahi/Experiment26-7B-GGUF/Experiment26-7B.Q4_K_M.gguf\",\"dagbs/dolphin-2.8-experiment26-7b-preview-GGUF/dolphin-2.8-experiment26-7b.Q4_K_M.gguf\",\"ggml-org/gemma-1.1-2b-it-Q4_K_M-GGUF/gemma-1.1-2b-it.Q4_K_M.gguf\",\"chenhunghan/TAIDE-LX-7B-Chat-GGUF/taide-lx-7b-chat.q4_k_m.gguf\",\"chenhunghan/TAIDE-LX-7B-Chat-GGUF/taide-lx-7b-chat.q8_0.gguf\",\"ggml-org/gemma-1.1-7b-it-Q4_K_M-GGUF/gemma-1.1-7b-it.Q4_K_M.gguf\",\"ggml-org/gemma-1.1-2b-it-Q8_0-GGUF/gemma-1.1-2b-it.Q8_0.gguf\",\"ggml-org/gemma-1.1-7b-it-Q8_0-GGUF/gemma-1.1-7b-it.Q8_0.gguf\",\"pi-null-mezon/openchat-3.5-0106-gemma-GGUF/ggml-model-Q8_0.gguf\",\"pi-null-mezon/openchat-3.5-0106-gemma-GGUF/ggml-model-Q4_K_M.gguf\",\"mlabonne/Gemmalpaca-2B-GGUF/gemmalpaca-2b.Q4_K_M.gguf\",\"LoneStriker/gemma-2b-GGUF/gemma-2b-Q4_K_M.gguf\",\"LoneStriker/gemma-2b-it-GGUF/gemma-2b-it-Q4_K_M.gguf\",\"LoneStriker/gemma-7b-GGUF/gemma-7b-Q4_K_M.gguf\",\"LoneStriker/gemma-7b-it-GGUF/gemma-7b-it-Q4_K_M.gguf\",\"mlabonne/Gemmalpaca-2B-GGUF/gemmalpaca-2b.Q4_K_M.gguf\",\"LoneStriker/OrcaGemma-2B-GGUF/OrcaGemma-2B-Q4_K_M.gguf\",\"rombodawg/EveryoneLLM-7b-Gemma-Base-GGUF/EveryoneLLM-7b-Gemma-Base-q6_k.gguf\",\"LoneStriker/openbuddy-gemma-7b-v19.1-4k-GGUF/openbuddy-gemma-7b-v19.1-4k-Q4_K_M.gguf\",\"LoneStriker/Gemmalpaca-7B-GGUF/Gemmalpaca-7B-Q4_K_M.gguf\", \"LoneStriker/zephyr-7b-gemma-v0.1-GGUF/zephyr-7b-gemma-v0.1-Q4_K_M.gguf\" ,\"Lewdiculous/firefly-gemma-7b-GGUF-IQ-Imatrix/firefly-gemma-7b-Q4_K_S-imatrix.gguf\"]\n",
        "\n",
        "\n",
        "\n",
        "model_id=\"SanctumAI/Phi-3-mini-4k-instruct-GGUF/phi-3-mini-4k-instruct.Q8_0.gguf\" #@param      [\"mradermacher/llava-v1.6-mistral-7b-GGUF/llava-v1.6-mistral-7b.Q4_K_M.gguf\",\"RDson/llava-llama-3-8b-v1_1-GGUF/llava-llama-3-8b-v1_1-Q8_0.gguf\",\"IHaveNoClueAndIMustPost/Llama-3-11.5B-Instruct-v2_GGUF/Replete-AI_Llama-3-11.5B-Instruct-v2-Q6_K.gguf\",\"PrunaAI/Llama-3-16B-GGUF-smashed/Llama-3-16B.Q8_0.gguf\",\"PrunaAI/Llama-3-16B-GGUF-smashed/Llama-3-16B.Q4_K_M.gguf\",\"SanctumAI/Phi-3-mini-4k-instruct-GGUF/phi-3-mini-4k-instruct.Q4_K_M.gguf\",\"mradermacher/Llama3-8B-DPO-uncensored-GGUF/Llama3-8B-DPO-uncensored.Q8_0.gguf\",\"mradermacher/Llama3-Inst-8B-DPO-Ultrafeedback-GGUF/Llama3-Inst-8B-DPO-Ultrafeedback.Q8_0.gguf\",\"DavidAU/Llama3-8B-OpenHermes-DPO-Q8_0-GGUF/llama3-8b-openhermes-dpo.Q8_0.gguf\",\"LoneStriker/OrpoLlama-3-8B-GGUF/OrpoLlama-3-8B-Q8_0.gguf\",\"MaziyarPanahi/WizardLM-2-7B-GGUF/WizardLM-2-7B.Q4_K_M.gguf\",\"SanctumAI/Phi-3-mini-4k-instruct-GGUF/phi-3-mini-4k-instruct.Q8_0.gguf\",\"MaziyarPanahi/WizardLM-2-7B-GGUF/WizardLM-2-7B.Q8_0.gguf\",\"FaradayDotDev/llama-3-8b-Instruct-GGUF/llama-3-8b-Instruct.Q4_K_M.gguf\",\"seyf1elislam/llama-3-neural-chat-v1-8b-GGUF/llama-3-neural-chat-v1-8b.Q4_K_M.gguf\",\"seyf1elislam/llama-3-neural-chat-v1-8b-GGUF/llama-3-neural-chat-v1-8b.Q8_0.gguf\",\"Quant-Cartel/Llama-3-8B-Instruct-DADA-iMat-GGUF/Llama-3-8B-Instruct-DADA-iMat-IQ4_XS.gguf\",\"Quant-Cartel/Llama-3-8B-Instruct-DADA-iMat-GGUF/Llama-3-8B-Instruct-DADA-iMat-Q8_0.gguf\",\"3thn/dolphin-2.9-llama3-8b-GGUF/dolphin-2.9-llama3-8b.Q4_K_M.gguf\",\"3thn/dolphin-2.9-llama3-8b-GGUF/dolphin-2.9-llama3-8b.Q8_0.gguf\",\"PawanKrd/Meta-Llama-3-70B-Instruct-GGUF/llama-3-70b-instruct.Q3_K_M.gguf\",\"twodgirl/zephyr-beta-wizardLM-2-merge-7B-Q6_K-GGUF/zephyr-beta-wizardlm-2-merge-7b.Q6_K.gguf\",\"MaziyarPanahi/WizardLM-2-8x22B-GGUF/WizardLM-2-8x22B.IQ1_M.gguf\",\"TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/dolphin-2.7-mixtral-8x7b.Q2_K.gguf\",\"TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/dolphin-2.7-mixtral-8x7b.Q4_K_M.gguf\",\"mradermacher/Starling-LM-alpha-8x7B-MoE-GGUF/Starling-LM-alpha-8x7B-MoE.Q4_K_M.gguf\",\"MaziyarPanahi/Qwen1.5-8x7b-v0.1-GGUF/Qwen1.5-8x7b-v0.1.Q4_K_M.gguf\",\"TheBloke/firefly-mixtral-8x7b-GGUF/firefly-mixtral-8x7b.Q4_K_M.gguf\",\"TheBloke/openbuddy-mixtral-8x7b-v15.1-GGUF/openbuddy-mixtral-8x7b-v15.1.Q4_K_M.gguf\",\"Quant-Cartel/Cerebrum-1.0-8x7b-iMat-GGUF/Cerebrum-1.0-8x7b-iMat-Q4_K_M.gguf\",\"MaziyarPanahi/Experiment26-7B-GGUF/Experiment26-7B.Q4_K_M.gguf\",\"dagbs/dolphin-2.8-experiment26-7b-preview-GGUF/dolphin-2.8-experiment26-7b.Q4_K_M.gguf\",\"ggml-org/gemma-1.1-2b-it-Q4_K_M-GGUF/gemma-1.1-2b-it.Q4_K_M.gguf\",\"chenhunghan/TAIDE-LX-7B-Chat-GGUF/taide-lx-7b-chat.q4_k_m.gguf\",\"chenhunghan/TAIDE-LX-7B-Chat-GGUF/taide-lx-7b-chat.q8_0.gguf\",\"ggml-org/gemma-1.1-7b-it-Q4_K_M-GGUF/gemma-1.1-7b-it.Q4_K_M.gguf\",\"ggml-org/gemma-1.1-2b-it-Q8_0-GGUF/gemma-1.1-2b-it.Q8_0.gguf\",\"ggml-org/gemma-1.1-7b-it-Q8_0-GGUF/gemma-1.1-7b-it.Q8_0.gguf\",\"pi-null-mezon/openchat-3.5-0106-gemma-GGUF/ggml-model-Q8_0.gguf\",\"pi-null-mezon/openchat-3.5-0106-gemma-GGUF/ggml-model-Q4_K_M.gguf\",\"mlabonne/Gemmalpaca-2B-GGUF/gemmalpaca-2b.Q4_K_M.gguf\",\"LoneStriker/gemma-2b-GGUF/gemma-2b-Q4_K_M.gguf\",\"LoneStriker/gemma-2b-it-GGUF/gemma-2b-it-Q4_K_M.gguf\",\"LoneStriker/gemma-7b-GGUF/gemma-7b-Q4_K_M.gguf\",\"LoneStriker/gemma-7b-it-GGUF/gemma-7b-it-Q4_K_M.gguf\",\"mlabonne/Gemmalpaca-2B-GGUF/gemmalpaca-2b.Q4_K_M.gguf\",\"LoneStriker/OrcaGemma-2B-GGUF/OrcaGemma-2B-Q4_K_M.gguf\",\"rombodawg/EveryoneLLM-7b-Gemma-Base-GGUF/EveryoneLLM-7b-Gemma-Base-q6_k.gguf\",\"LoneStriker/openbuddy-gemma-7b-v19.1-4k-GGUF/openbuddy-gemma-7b-v19.1-4k-Q4_K_M.gguf\",\"LoneStriker/Gemmalpaca-7B-GGUF/Gemmalpaca-7B-Q4_K_M.gguf\", \"LoneStriker/zephyr-7b-gemma-v0.1-GGUF/zephyr-7b-gemma-v0.1-Q4_K_M.gguf\" ,\"Lewdiculous/firefly-gemma-7b-GGUF-IQ-Imatrix/firefly-gemma-7b-Q4_K_S-imatrix.gguf\"]\n",
        "\n",
        "def selectPath(paths=modelsPaths):\n",
        "    #return \"gemma-openchat7v-model-Q4_K_M.gguf\"\n",
        "    ls=paths\n",
        "    #c='termux-dialog radio -v \"%s\" -t \"Select model\"' % \",\".join(ls)\n",
        "    #v=eval(os.popen(c).read())[\"text\"]\n",
        "    for i,t in enumerate(ls):print (\"%s) %s\" % (i ,t) )\n",
        "    print (\"input the number :\")\n",
        "    v=ls[int(input())]\n",
        "\n",
        "    return v\n",
        "if not IN_COLAB:\n",
        "    model_id=selectPath()\n",
        "def downHgFile(url,targetDir=modelsPath):\n",
        "    fileName=Path (model_id ).name\n",
        "    repo =model_id[:-len(fileName)-1]\n",
        "    print(fileName,repo)\n",
        "    fileExists=os.path.exists(os.path.join(targetDir,fileName))\n",
        "\n",
        "    print(repo,fileName,fileExists )\n",
        "    if not fileExists:\n",
        "        print (\"Downloading file :\")\n",
        "        hf_hub_download(repo ,filename=fileName,local_dir=targetDir,local_dir_use_symlinks=False)\n",
        "max_tokens=4096 # @param {type:\"integer\",min:10, max:8192}\n",
        "n_ctx=4096 # @param {type:\"integer\",min:10, max:8192}\n",
        "downHgFile(model_id )\n",
        "#hf_hub_download(\"lovelyai999/temp\" ,filename=\"mistral_7b_mmproj-v1_5_Q4_1.gguf\",local_dir=\"./\",local_dir_use_symlinks=False)\n",
        "modelPath=os.path.join(modelsPath,Path(model_id).name)\n",
        "if (\"8x\" in model_id or \"70b\" in model_id) and torch.cuda.is_available():\n",
        "    n_gpu_layers=16\n",
        "    if  \"70b\" in model_id:\n",
        "        n_gpu_layers=24\n",
        "    n_threads=4\n",
        "if \"/llava\" in model_id:\n",
        "    if not os.path.exists(\"mistral_7b_mmproj-v1_5_Q4_1.gguf\"):hf_hub_download(\"lovelyai999/temp\" ,filename=\"mistral_7b_mmproj-v1_5_Q4_1.gguf\",local_dir=\"./\",local_dir_use_symlinks=False)\n",
        "    chat_handler = Llava15ChatHandler(clip_model_path=\"mistral_7b_mmproj-v1_5_Q4_1.gguf\",verbose=True)\n",
        "    model = Llama(modelPath,n_gpu_layers=n_gpu_layers,n_threads=n_threads,max_tokens=4096,logits_all=True,n_ctx=n_ctx,chat_handler=chat_handler)\n",
        "else:\n",
        "    model = Llama(modelPath,n_gpu_layers=n_gpu_layers,n_threads=n_threads,max_tokens=4096,logits_all=True,n_ctx=n_ctx)\n",
        "#draft_model=LlamaPromptLookupDecoding(num_pred_tokens=10) )\n",
        "\n",
        "tokenizer = model.tokenize\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "from threading import Thread\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "partial_message = \"\"\n",
        "\n",
        "def predict(message, history,top_k=300, top_p=0.95, temp=0.85, repeat_penalty=1.1,max_tokens=max_tokens):\n",
        "    global partial_message,model_id\n",
        "    try :messageT=message[\"text\"]\n",
        "    except :messageT=message\n",
        "    global model_id\n",
        "    if \"phi-3-\" in model_id:\n",
        "        prompt=f\"<|user|>{messageT}<|end|><|assistant|>\"\n",
        "    else:\n",
        "        prompt=f\"\"\"### System:\n",
        "You are a professional private assistant.\n",
        "### User:\n",
        "{messageT}\n",
        "###  Response:\n",
        "\n",
        "\"\"\"\n",
        "    prompt_=f\"\"\"\n",
        "###Below is an instruction that describes my question or task.\n",
        "Write a response that appropriately completes the request:\n",
        "{messageT}\n",
        "### Response :\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    print (message)\n",
        "    #model_inputs = tokenizer(prompt.encode(\"utf-8\"))\n",
        "    #generate_kwargs = dict(top_k=top_k, top_p=top_p, temp=temp, repeat_penalty=repeat_penalty)\n",
        "    stop= [\"<|end|>\" ,\"<|end_of_text|>\", \"<|im_end|>\"  ]\n",
        "    if model_id in [\"FaradayDotDev/llama-3-8b-Instruct-GGUF/llama-3-8b-Instruct.Q4_K_M.gguf\",\"l3utterfly/llama-3-8b-Instruct-gguf/llama-3-8b-Instruct-Q4_K.gguf\",\"l3utterfly/llama-3-8b-Instruct-gguf/llama-3-8b-Instruct-Q8_0.gguf\",\"PawanKrd/Meta-Llama-3-70B-Instruct-GGUFFaradayDotDev/llama-3-8b-Instruct-GGUF/llama-3-70b-instruct.Q2_K.gguf\",\"PawanKrd/Meta-Llama-3-70B-Instruct-GGUF/llama-3-70b-instruct.Q3_K_M.gguf\", \"LoneStriker/OrpoLlama-3-8B-GGUF/OrpoLlama-3-8B-Q8_0.gguf\" ,\"mradermacher/Llama3-8B-DPO-uncensored-GGUF/Llama3-8B-DPO-uncensored.Q8_0.gguf\",\"mradermacher/Llama3-Inst-8B-DPO-Ultrafeedback-GGUF/Llama3-Inst-8B-DPO-Ultrafeedback.Q8_0.gguf\",\"DavidAU/Llama3-8B-OpenHermes-DPO-Q8_0-GGUF/llama3-8b-openhermes-dpo.Q8_0.gguf\",\"RDson/llava-llama-3-8b-v1_1-GGUF/llava-llama-3-8b-v1_1-Q8_0.gguf\",\"IHaveNoClueAndIMustPost/Llama-3-11.5B-Instruct-v2_GGUF/IHaveNoClueAndIMustPost/Replete-AI_Llama-3-11.5B-Instruct-v2-Q6_K.gguf\",\"PrunaAI/Llama-3-16B-GGUF-smashed/Llama-3-16B.Q8_0.gguf\",\"PrunaAI/Llama-3-16B-GGUF-smashed/Llama-3-16B.Q4_K_M.gguf\" ]:\n",
        "        stop=[\"### Below\",\".\\n\\n\",\"assistant\\n\\n\",\"!\\n\\n\",\"<|end|>\" ,\"<|end_of_text|>\" ,\"<|im_end|>\",\"System:\"   ]\n",
        "    generate_kwargs=dict (suffix=None, max_tokens=max_tokens, temperature=temp, top_p=top_p, min_p=0.05, typical_p=1.0, logprobs=None, echo=False, stop=stop, frequency_penalty=0,presence_penalty=0.0, repeat_penalty=1.1, top_k=top_k, stream=True , seed=None, tfs_z=1.0, mirostat_mode=0, mirostat_tau=5.0, mirostat_eta=0.1, model=None, stopping_criteria=None, logits_processor=None, grammar=None, logit_bias=None)\n",
        "\n",
        "\n",
        "    partial_message = \"\"\n",
        "    if isinstance(message,dict) and message[\"files\"] and message[\"files\"][0][\"path\"] and message[\"files\"][0]['mime_type'].startswith(\"image\"):\n",
        "        messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an assistant who perfectly describes images.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\":message[\"files\"][0][\"path\"]}},\n",
        "                {\"type\" : \"text\", \"text\": messageT}\n",
        "            ]\n",
        "        }]\n",
        "        outputs =model.create_completion(json.dumps (messages),**generate_kwargs)\n",
        "    else:\n",
        "        outputs =model.create_completion(prompt ,**generate_kwargs)\n",
        "\n",
        "\n",
        "    for chunk in outputs:\n",
        "        #print (chunk )\n",
        "        content = chunk[\"choices\"][0][\"text\"]\n",
        "        #print(content,repr(content ))\n",
        "        if content:\n",
        "            partial_message+=content\n",
        "            yield partial_message\n",
        "    \"\"\"\n",
        "    for new_token in model.generate(model_inputs,**generate_kwargs):\n",
        "            #print (new_token)\n",
        "            if new_token in (213,7221,1):break\n",
        "            s=model.detokenize([new_token])\n",
        "            #print (s)\n",
        "            if isinstance(s,bytes):\n",
        "                try:partial_message += s.decode(\"utf-8\")\n",
        "                except :break\n",
        "            yield partial_message\n",
        "        \"\"\"\n",
        "\n",
        "chatbot = gr.Chatbot(likeable=True,show_copy_button=True)\n",
        "textbox = gr.Textbox (show_copy_button=True)\n",
        "\n",
        "user=\"brian\" #@param {type:\"string\"}\n",
        "password=\"pwd\" #@param {type:\"string\"}\n",
        "auth=(user,password)\n",
        "\n",
        "gr.ChatInterface(predict,chatbot=chatbot,stop_btn=\"Stop\" ,retry_btn=\"Retry\",concurrency_limit=1,description=description,\n",
        "additional_inputs=[gr.Number(value=100,minimum =0,maximum =1000,precision=0,show_label=True ,label=\"Topic K\"),\n",
        "gr.Number(value=0.85,minimum =0,maximum =1,precision=3,show_label=True ,label=\"Topic P\"),\n",
        "gr.Number(value=0.85,minimum =0,maximum =1,precision=3,show_label=True ,label=\"Temperature\"),gr.Number(value=1.1,minimum =1,maximum =3,precision=3,show_label=True ,label=\"Repeat penalty\") ,gr.Number(value=4096,minimum =0,maximum =8192,precision=0,show_label=True ,label=\"max_tokens\") ],multimodal=True ).launch(debug=True,share=False ,inline=True )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOAg6La75CPwF1s7wcp+NIP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc1cbff218154d019b903f815856fe44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a23a08f936da48088f06610469159420",
              "IPY_MODEL_ee6e62eb1b294334a83722ece56c0556",
              "IPY_MODEL_4c1edaf855444fe49d3b8c962b88e745"
            ],
            "layout": "IPY_MODEL_ddc6f8ad6c7b4efca113a48952b82d3d"
          }
        },
        "a23a08f936da48088f06610469159420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c73f60b02edd4aed8abc130617ab6362",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_24d3bef8015e4a19bfb8e23d46ed621d",
            "value": "phi-3-mini-4k-instruct.Q8_0.gguf:‚Äá‚Äá64%"
          }
        },
        "ee6e62eb1b294334a83722ece56c0556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef71584f1c9c40a1adcb1b0166ad17ea",
            "max": 4061226880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0592ff1b391417e83c262a17fe46666",
            "value": 2579496960
          }
        },
        "4c1edaf855444fe49d3b8c962b88e745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dc794c447fe416486926f593478359d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_46a1c615f2c14d489dc906b4cd9258fa",
            "value": "‚Äá2.58G/4.06G‚Äá[00:21&lt;00:12,‚Äá118MB/s]"
          }
        },
        "ddc6f8ad6c7b4efca113a48952b82d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c73f60b02edd4aed8abc130617ab6362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d3bef8015e4a19bfb8e23d46ed621d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef71584f1c9c40a1adcb1b0166ad17ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0592ff1b391417e83c262a17fe46666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dc794c447fe416486926f593478359d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a1c615f2c14d489dc906b4cd9258fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}